---
title: "Making statistics work for (evolutionary language) scientists"
subtitle: "TTF DataScience, WP Statistics"
author: "Erik J. Ringen"
format:
  revealjs:
    auto-stretch: false
    incremental: true
    slide-number: true
    theme: default
    smaller: true
    margin: 0.05
---

## Introduction

This session is about how statistics can be in service of science.

- Key ideas:
    - Scientist learn the language of statistical models in order to do their work
    - But a lot gets lost in translation when we try to translate back to substantive scientific questions from the output of statistical models

- Goals:
    - Part 1: Teach you a general method to translate statistical models back into substantive scientific questions using `marginaleffects`
    - Part 2: Managing the workflow of statistical computing using `targets`

## What this session is *not* about

- Promoting any particular statistical model
- Telling you what you 'should' be studying (statistician's fallacy)
- Bayesian statistics

# Software

::: {.nonincremental}
In this session I will use:

- R (latest version)
- The following R packages:
    - `marginaleffects`
    - `tidyverse`
    - `targets`
    - `mgcv` (tangentially)
    - `knitr` (for rendering outputs)

Quarto markdown and code here (optional):
:::

# Part 1: Marginal effects

## About me

- I earned my PhD in Evolutionary Anthropology <span class="fragment strike">during the 433rd lunation of the third millennium, when Mars was at an orbital longitude of ~311 degrees</span><span class="fragment"> in May 2022</span> 

- To get from Zurich to here, I travelled <span class="fragment strike">807 light-microseconds</span><span class="fragment"> 242 kilometers</span>

- The units we use to communicate matter!

## The way we report statistics is often confusing (and misleading)

![](figures/confusing_stats.png)

## The way we report statistics is often confusing (and misleading)

![](figures/regression_table.png)

---

### In contrast, descriptive statistics and data viz are easy to understand

```{r}
#| out.width: "60%"
set.seed(123)
library(tidyverse)
N <- 250

multilingual <- sample(c(0, 1), N, replace = TRUE)

age <- runif(N, 7, 12)
age_s <- (age - mean(age)) / sd(age)
age_c <- age - mean(age)
cognitive_flexibility <- rnorm(N, multilingual*0.3 + age_s*multilingual*0.2 + age_s*0.1, 0.5)
cognitive_flexibility  <- pnorm(cognitive_flexibility) * 100

d <- data.frame(multilingual = ifelse(multilingual == 0, "monolingual", "multilingual"), cognitive_flexibility = cognitive_flexibility, age = age, age_c = age_c)

theme_set(theme_classic(base_size = 24))

ggplot(d, aes(x = multilingual, y = cognitive_flexibility, color = multilingual)) +
    geom_jitter(alpha = 0.7, width = 0.05) +
    geom_boxplot(alpha = 0.1) +
    theme(legend.position = "none") +
    labs(x = "", y = "Cognitive flexibility score")

# export data for targets example
write_csv(d, "data/cognitive_flexibility.csv")
```

'`r paste0("Monolingual participants have a mean cognitive flexibility score of ", 
           round(mean(d$cognitive_flexibility[d$multilingual=="monolingual"]), 2),
           " (SD = ", 
           round(sd(d$cognitive_flexibility[d$multilingual=="monolingual"]), 2),
           "), while multilingual participants have a mean score of ", 
           round(mean(d$cognitive_flexibility[d$multilingual=="multilingual"]), 2),
           " (SD = ",
           round(sd(d$cognitive_flexibility[d$multilingual=="multilingual"]), 2),
           ").")`'

- Simple comparisons with scientifically-meaningful units.
- What if we could do the same for statistical models?

## Predictions, not parameters
- The central idea: rather than directly interpret parameters, use the model to make predictions
    - contrasts between different predictions consitute *marginal effects*
- The `marginaleffects` package by Vincent Arel-Bundock makes these calculations easy for a wide range of models in both R and Python.

![](figures/model_to_meaning.png){width="65%"}

## In simple models, a parameter might be all we need

:::: {.columns}
::: {.column width="60%"}
- Example: do multilingual children have greater cognitive flexibility than monolingual children?
    - *Data*: 200 children from some population
    - *Estimand*: what is the average difference in cognitive flexibility (measured by a psychometric instrument ranging from 0 to 100) between multilingual and monolingual children?
    - *Estimate*: 'Multilingual participants have an average cognitive flexibility score of `r round(coef(lm(cognitive_flexibility ~ multilingual))["multilingual"], 3)` [`r round(confint(lm(cognitive_flexibility ~ multilingual))["multilingual",1], 3)`, `r round(confint(lm(cognitive_flexibility ~ multilingual))["multilingual",2], 3)`] points higher than monolingual participants.'
:::

::: {.column width="40%"}
::: {.fragment}
```{r, echo=FALSE}
ggplot(d, aes(x = multilingual, y = cognitive_flexibility, color = multilingual)) +
    geom_jitter(alpha = 0.7, width = 0.05) +
    geom_boxplot(alpha = 0.1) +
    theme(legend.position = "none") +
    labs(x = "", y = "Cognitive flexibility")
```
:::

::: {.fragment}
```{r}
summary(lm(cognitive_flexibility ~ multilingual))
```
:::
:::
::::

## A regression is a machine that makes predictions

$$ \text{Cognitive flexibility} = \alpha + \beta \times \text{Multilingual} + \epsilon $$
$$ \epsilon \sim \text{Normal}(0, \sigma^2) $$

- The parts of the machine are the parameters ($\alpha, \beta, \sigma$):
  - To make a prediction for a monolingual child, just take the intercept ($\alpha$).
  - To make a prediction for a multilingual child, add the coefficient for multilingual ($\beta$) to the intercept.
- Linear regression is such a simple machine that it offers a 1:1 mapping between the parameters and the estimand (average difference between multilingual and monolingual children).

## Interactions

![](figures/hall_of_mirrors.png){width="80%"}

## Interactions imply heterogeneity

:::: {.columns}

::: {.column width="60%"}
- For a given child, let $Y_i(\text{multilingual})$ be the outcome if the child is multilingual and $Y_i(\text{monolingual})$ be the outcome if the child is monolingual. 

- The estimand is the average difference in potential outcomes: $\frac{1}{N} \sum_{i=1}^N [Y_i(\text{multilingual}) - Y_i(\text{monolingual})]$. Known as the *average treatment effect* (ATE), or average marginal effect (AME).

- In our simple linear regression, all children are identical, conditional on their mono/multilingual status, which allows us to reduce the estimand to a single parameter.
:::

::: {.column width="40%"}
::: {.fragment}
![](figures/ATE.png){width="75%"}
:::
:::

::::

## Interactions imply heterogeneity

:::: {.columns}
::: {.column width="60%"}
```{r}
m_centered <- lm(cognitive_flexibility ~ multilingual * age_c)

summary(m_centered)
```
:::

::: {.column width="40%"}
```{r}
ggplot(d, aes(x = age_c, y = cognitive_flexibility, color = multilingual)) +
    geom_point(alpha = 0.7) +
    geom_smooth(method = "lm", se = FALSE) +
    theme(legend.title = element_blank()) +
    scale_color_manual(values = c("monolingual" = "royalblue", 
                                "multilingual" = "darkorange")) +
    labs(x = "Age (centered)", y = "Cognitive flexibility")
```
:::
::::

- Which coefficient corresponds to the estimand (average marginal effect)?
    - None! The AME depends on the distribution of the moderator (age):
        - The magnitude of the multilingual effect depends on age--now it matters which children we are averaging over.

## Meaning of interaction term is highly contextual

On the previous slide, the interaction term was mean-centered. What if we use the raw age variable instead?

:::: {.columns}
::: {.column width="60%"}
```{r}
m_uncentered <- lm(cognitive_flexibility ~ multilingual * age)

summary(m_uncentered)
```
:::

::: {.column width="40%"}
```{r}
ggplot(d, aes(x = age, y = cognitive_flexibility, color = multilingual)) +
    geom_point(alpha = 0.7) +
    geom_smooth(method = "lm", se = FALSE) +
    theme(legend.title = element_blank()) +
    scale_color_manual(values = c("monolingual" = "royalblue", 
                                "multilingual" = "darkorange")) +
    labs(x = "Age", y = "Cognitive flexibility")
```
:::
::::

## Getting started with `marginaleffects`: predictions

```{r, echo = T}
library(marginaleffects)

uncentered_model <- lm(cognitive_flexibility ~ multilingual * age, data = d)

preds <- predictions(uncentered_model)

preds |> 
    as.data.frame() |> 
    select(rowid, multilingual, age, estimate, conf.low, conf.high) |> 
    knitr::kable(digits = 2)
```

## Getting started with `marginaleffects`: predictions

```{r, echo = T}
library(marginaleffects)

centered_model <- lm(cognitive_flexibility ~ multilingual * age_c, data = d)

preds <- predictions(centered_model)

preds |> 
    as.data.frame() |> 
    select(rowid, multilingual, age_c, estimate, conf.low, conf.high) |> 
    knitr::kable(digits = 2)
```

## From predictions to comparisons

```{r, echo = T}
comparisons <- comparisons(uncentered_model, variables = "multilingual")

comparisons |> 
    as.data.frame() |> 
    select(rowid, contrast, age, estimate, conf.low, conf.high) |> 
    knitr::kable(digits = 2)
```

## Calcualting average marginal effects

```{r, echo = T}
AME <- avg_comparisons(uncentered_model)

AME |> 
    as.data.frame() |> 
    select(term, contrast, estimate, conf.low, conf.high) |> 
    knitr::kable(digits = 2)
```

## marginaleffects can also make plots

```{r, echo = T}
plot_predictions(uncentered_model, condition = list("multilingual"))
```

## marginaleffects can also make plots

```{r, echo = T}
plot_predictions(uncentered_model, condition = list("age"))
```

## marginaleffects can also make plots

```{r, echo = T}
plot_predictions(uncentered_model, condition = list("age", "multilingual"))
```

## marginaleffects can also make plots

Because the plots are made with `ggplot2`, we can customize them as we like.

```{r, echo = T}
#| out.width: "75%"
plot_predictions(uncentered_model, condition = list("age", "multilingual")) +
    theme(legend.title = element_blank()) +
    scale_color_manual(values = c("monolingual" = "royalblue", 
                                "multilingual" = "darkorange")) +
    scale_fill_manual(values = c("monolingual" = "royalblue", 
                                "multilingual" = "darkorange")) +
    labs(x = "Age", y = "Cognitive flexibility score")
```

## Generalized linear models

:::: {.columns}

::: {.column width="60%"}
- GLMs such as logistic regression and Poisson regression are also supported by `marginaleffects`.

- Good news for us, because *everything* interacts in a GLM due to the link function (e.g., logit, log, softmax). 
    - Extremely easy to mislead ourselves if we try to interpret parameters.
:::

::: {.column width="40%"}
![](figures/inference.jpg)
:::

::::

## Logistic regression

- Hypothetical dataset: Touchscreen experiment with Chimpanzees
    - After viewing a stimulus, the chimpanzee touches the screen on either the 'Agent' or the 'Patient' in a scence.
    - Estimand: what is the average *difference* in the probability of touching the 'Agent' side between two conditions ('experimental' vs 'control')?
        - $\frac{1}{N} \sum_{i=1}^N [P(Y_i = \text{Agent} | \text{experimental}) - P(Y_i = \text{Agent} | \text{control})]$

![](figures/chimp_touchscreen.webp){width="50%"}

## Logistic regression

```{r}
N <- 60

condition <- rep(c("experimental", "control"), N/2)
sex <- sample(c("male", "female"), N, prob = c(0.35, 0.65), replace = TRUE)
mu <- 0.4 + (1.5 * (condition == "experimental")) + (0.25 * (sex == "male"))

agent <- rbinom(N, 1, plogis(mu))

d <- data.frame(agent = agent, condition = condition, sex = sex)
```

$$ \text{Agent} \sim \text{Bernoulli}(\pi) $$
$$ \pi = \text{logit}^{-1}(\alpha + \beta \times \text{experimental}) $$

```{r}
logistic_model <- glm(agent ~ condition, data = d, family = binomial(link = "logit"))

summary(logistic_model)
```

## Logistic regression

![](figures/logistic_compression.png){width="50%"}

- Even with just a single predictor, we cannot get our estimate from looking at model coefficients. 

- Due to the link function, the effect of the experimental condition depends on the intercept.

- 'Mechanistic' rather than conceptual interaction.
    - To get the AME we need to calculate:
        - $\frac{1}{1 + e^{-(\alpha + \beta \times \text{experimental})}} - \frac{1}{1 + e^{-\alpha}}$

## Logistic regression

The marginal effect on the probability scale for a log odds ratio of `r round(coef(logistic_model)["conditionexperimental"], 2)` depends strongly on the intercept!

```{r}
par(cex = 1.5)
curve(plogis(x + coef(logistic_model)["conditionexperimental"]) - plogis(x), from = -5, to = 5, xlab = "Intercept (log odds scale)", ylab = "AME (probability scale)")
```
        
## *marginaleffects* to the rescue

```{r, echo = T}
AME <- avg_comparisons(logistic_model, variables = "condition")

AME |> 
    as.data.frame() |> 
    select(term, contrast, estimate, conf.low, conf.high) |> 
    print(digits = 2)
```

```{r, echo = T}
#| out.width: "70%"
plot_predictions(logistic_model, condition = list("condition")) + ylab("Pr(Agent)")
```

- NOTE: I should write out the estimate in line with the original goal to make the outputs easier to report and interpret.

## But how does it work?

- For frequentist models, `marginaleffects` by default uses the delta method (Taylor series expansion)
    - Various bootstrap and weighting methods supported

- For Bayesian models (e.g., fit with `brms`), `marginaleffects`, uses full posterior draws

- More info: https://marginaleffects.com/chapters/uncertainty.html

## Review thus far

Reporting model results using `marginaleffects`:

- Makes your model results easier to communicate
- Avoid misinterpreting the *magnitude* of effects
- Avoid misinterpreting the *direction* of effects

## Non-linear effects

Example: relationship between population density and structural diversity in language (measured by normalized entropy)

```{r}
library(MASS)  # for mvrnorm

# Generate synthetic data
set.seed(123)
n <- 200

# Create log-scaled population density
log_density <- runif(n, -2, 8)

# Create covariance matrix using squared exponential kernel
dist_mat <- as.matrix(dist(log_density))
sigma <- 0.55    # increased variance
l <- 0.20       # decreased length scale for more wiggles
K <- sigma^2 * exp(-dist_mat^2 / (2*l^2))

# Generate smooth function values using Gaussian process
diag(K) <- diag(K) + 0.5
gp_component <- mvrnorm(1, mu=rep(0, n), Sigma=K)

# Add linear trend and normalize
linear_trend <- 0.3 * log_density  # linear component
combined <- gp_component + linear_trend
structural_diversity <- plogis(combined)

# Create data frame
d <- data.frame(
  log_density = log_density,
  structural_diversity = structural_diversity
)

# Plot
ggplot(d, aes(x=log_density, y=structural_diversity)) +
  geom_point(alpha=0.7) +
  geom_smooth(method="gam", formula = y ~ s(x, k=8)) +  # increased k for more wiggles
  labs(x="Log population density", 
       y="Structural diversity\n(normalized entropy)") +
  ylim(0, 1)
```

## Non-linear effects

```{r}
#| out.width: "60%"
library(mgcv)
gam_model <- mgcv::gam(structural_diversity ~ s(log_density, k = 8))

summary(gam_model)
```

## Non-linear effects

```{r, echo = T}
#| out.width: "30%"
slopes_df <- slopes(gam_model) |> 
    as.data.frame() |> 
    dplyr::select(estimate, conf.low, conf.high, log_density, structural_diversity)

print(head(slopes_df), digits = 2)
```

```{r}
#| out.width: "80%"
# Create segments for slopes
slope_segments <- slopes_df |>
    dplyr::slice(seq(1, n(), by = 10)) |>
    mutate(
        x_start = log_density - 0.25,
        x_end = log_density + 0.25,
        y_start = structural_diversity - (0.25 * estimate),
        y_end = structural_diversity + (0.25 * estimate)
    )

ggplot() +
    # Original data points
    geom_point(data = d, aes(x = log_density, y = structural_diversity), 
               alpha = 0.3) +
    # GAM smooth
    geom_smooth(data = d, aes(x = log_density, y = structural_diversity),
                method = "gam", formula = y ~ s(x, k=8), color = "blue") +
    # Slope segments
    geom_segment(data = slope_segments,
                aes(x = x_start, xend = x_end, 
                    y = y_start, yend = y_end),
                color = "red", size = 1) +
    labs(x = "Log population density",
         y = "Structural diversity")
```

## Non-linear effects: average slopes

$\mathbb{E}\left[\frac{\partial \text{structural diversity}}{\partial \text{ log pop density}}\right]$

```{r, echo = T}
avg_slopes(gam_model) |> 
    as.data.frame() |> 
    dplyr::select(term, estimate, conf.low, conf.high) |> 
    knitr::kable(digits = 2)
```


## The bigger picture

- Directly interpreting statistical models is a full of traps that can mislead us. Working with predictions and marginal effects allows us to avoid many of these traps.

- marginaleffects can be used with a huge array of models:
    - linear models, generalized linear models  (e.g., `lm`, `glm`)
    - generalized additive models (e.g., `mgcv`, `gamm4`)
    - multilevel models (e.g., `lme4`, `glmmTMB`)
    - Bayesian models (e.g., `brms`)
    - machine learning models (e.g., `tidymodels`, `mlr3`)

## Can marginal effects improve the reliability of science?

- On the one hand, we can avoid falling into many of the traps of interpreting model parameters.

- On the other hand, this way of doing things brings the *estimand* into focus. We are being more explicit about the quantity we are trying to estimate--*which is not tied to any particular model.*

## Red Card Dataset

2,053 soccer players in the first male divisions of England, Germany, France, and Spain in the 2012–2013 season.

Outcome: number of red cards recieved for 146,028 player-referee dyads.

Covariates: player and referee traits, match statistics

![](figures/red_card_in_soccer.jpg){width="50%"}

## Many analysts, many estimates

"Are soccer players with dark skin tone more likely than those with light skin tone to receive red cards from referees?"

![](figures/many_analysts_title.png){width="65%"}

## Many analysts, many estimates

"Are soccer players with dark skin tone more likely than those with light skin tone to receive red cards from referees?"

![](figures/many_analysts_results.jpeg){width="80%"}

----

![](figures/hidden_universe_uncertainty.png){width="80%"}

----

## Who watches the watchmen? Reanalysis of the meta-analysis

![](figures/many_analysts_reanalysis.png){width="80%"}

## Many analysts, many *estimands*

![](figures/causal_diagrams_RQ.jpeg){width="80%"}

"Thus, we argue that the results obtained in the CSI showed such a large variation because the 29 teams pursued (at least) four different research questions and therefore used different research designs."

----

![](figures/many_analysts1.png){width="80%"}

----

Controlled direct effect: $E[Y(\text{dark}) - Y(\text{light}) | M = m]$; 486 parametric models

![](figures/many_analysts2.png){width="75%"}

## 

Causal (not statistical) assumptions needed to inform research design

![](figures/DAG_triangle.png)

----

![Three critical choices in quantitative research. From: Lundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532-565.](figures/estimand_flow.png)


## Breakout session (10-15 minutes)

::: {.nonincremental}

Goals:

(1) Write down the *estimand* for one of your research questions
    - Remember: this is a unit-specific comparison, ideally with reference to a specific population.

(2) Draft a statistical model that you could use as your *estimator*
    - Write down the marginaleffects code that would yield your *estimate*
    - If you don't have the relevant software on your laptop, find a neighbor who does.
    - Pseudocode is fine!

:::

## Report-back/Q&A session

- How did it go? What friction did you encounter?

# Part 2: Towards a less stressful computational workflow

---

Statistics can feel like a thankless list of things that all have to be right or else *nothing* is right.
- Not totally wrong, but leads to anxiety

- Calls to improve statistical practice in science imply time commitments:
    - More time for training
    - More time for coding tasks (recall the multiverse)

## Academic time allocation

![](figures/time_allocation.png){width="60%"}

Brauer, K. (2021). " I'll Finish It This Week" And Other Lies. arXiv preprint arXiv:2103.16574.

## Harsh realities

- Time allocation is a zero-sum game
    - Time spent on doing better statistics is time that could be spent on the many other aspects of science and professional development

- If raise the bar on statistical pracitce we need workflows that are reproducible, understandable, and which reduce cognitive burden.

## The tangled web of data analysis

![](figures/tangled_web.png){width="75%"}

- What happens when Reviewer #2 asks for a change to the data/model?

## `targets`

Package for reproducible research pipelines by Will Landau:

- Encodes every step of your data analysis as a directed acyclic graph

- Automatically detection of dependencies, which means:
    - If you change some part of your pipeline, `targets` will rerun (only) the parts that depend on the changed part.

## Cognitive flexibility example

```{r, eval = F, echo = T}
# _targets.R file
library(targets)

tar_source() # load the R scripts in my dir
tar_option_set(packages = c("tidyverse", "marginaleffects")) # load any packages used
# define pipeline
list(
    tar_target(data_file, "data/cognitive_flexibility.csv", format = "file"),
    tar_target(data, read_csv(data_file)),
    tar_target(model, fit_model(data)),
    tar_target(treatment_effect, avg_comparisons(model, newdata = data, variables = "multilingual")),
    tar_target(model_plot, plot_predictions(model, condition = list("multilingual")))
)
```

## tar_visnetwork()

```{r}
library(targets)
# tar_delete(everything()) # reset the pipeline
```

```{r, echo=T}
tar_visnetwork()
```

## Looking inside in the pipeline?

```{r, echo=T, eval = F}
# fit_model.R
fit_model <- function(data, age_moderator = TRUE){
    if(age_moderator){
        model <- lm(agent ~ condition * age, data = data)
    } else {
        model <- lm(agent ~ condition, data = data)
    }
    return(model)
}
```

## Running the pipeline
```{r, echo=T}
tar_make()
```

```{r, echo=T}
tar_visnetwork()
```

## See what happens if we change the data

```{r, echo=T}
# remove anomalous observations
problematic_obs <- c(3, 15, 27)

write_csv(d[-problematic_obs,], "data/cognitive_flexibility.csv")
```

## See what happens if we change the data

```{r, echo=T}
tar_visnetwork()
tar_outdated()
```

```{r, results = "hide"}
tar_make()
```

## See what happens if we change the model function

```{r, echo=T}
# R/fit_model.R
fit_model <- function(data, age_moderator = TRUE){
    if(age_moderator){
        model <- lm(cognitive_flexibility ~ multilingual * poly(age, 2), data = data)
    } else {
        model <- lm(cognitive_flexibility ~ multilingual, data = data)
    }
    return(model)
}
```

## Example of how this works at scale (Vanessa paper)

## Advanced use of `targets`

- Dynamic branching patterns, when there are too many targets to specify manually

- Great support for parallel processing using `future`

## Conclusion / Q&A





