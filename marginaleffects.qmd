---
title: "Making statistics work for (evolutionary language) scientists"
author: "Erik J. Ringen"
format:
  revealjs:
    auto-stretch: false
    incremental: true
    slide-number: true
    theme: default
    smaller: true
---

## Introduction

This session is about how statistics can be in service of science.

- Key ideas:
    - Scientist learn the language of statistical models in order to do their work
    - But a lot gets lost in translation when we try to translate back to substantive scientific questions from the output of statistical models

- Goals:
    - Part 1: Teach you a very general method to translate statistical models back into substantive scientific questions
    - Part 2: Discuss the workflow of statistical computing

# Part 1: Marginal effects

## About me

- I earned my PhD in Evolutionary Anthropology <span class="fragment strike">during the 447th lunation of the third millennium, when Mars was at an orbital longitude of ~187 degrees</span><span class="fragment"> in May 2023</span>

- To get from Zurich to here, I travelled <span class="fragment strike">807 light-microseconds</span><span class="fragment"> 242 kilometers</span>

## The way we report statistics is often confusing (and misleading)

![](figures/confusing_stats.png)

## The way we report statistics is often confusing (and misleading)

![](figures/regression_table.png)

---

### In contrast, descriptive statistics and data viz are easy to understand

```{r}
set.seed(123)
library(tidyverse)
N <- 250

multilingual <- sample(c(0, 1), N, replace = TRUE)

age <- runif(N, 7, 12)
age_s <- (age - mean(age)) / sd(age)
age_c <- age - mean(age)
cognitive_flexibility <- rnorm(N, multilingual*0.3 + age_s*multilingual*0.2 + age_s*0.1, 0.5)
cognitive_flexibility  <- pnorm(cognitive_flexibility) * 100

d <- data.frame(multilingual = ifelse(multilingual == 0, "monolingual", "multilingual"), cognitive_flexibility = cognitive_flexibility, age = age, age_c = age_c)

ggplot(d, aes(x = multilingual, y = cognitive_flexibility, color = multilingual)) +
    geom_jitter(alpha = 0.7, width = 0.05) +
    geom_boxplot(alpha = 0.1) +
    theme_classic(base_size = 24) +
    theme(legend.position = "none") +
    labs(x = "", y = "Cognitive flexibility score")
```

'`r paste0("Monolingual participants have a mean cognitive flexibility score of ", 
           round(mean(d$cognitive_flexibility[d$multilingual=="monolingual"]), 2),
           " (SD = ", 
           round(sd(d$cognitive_flexibility[d$multilingual=="monolingual"]), 2),
           "), while multilingual participants have a mean score of ", 
           round(mean(d$cognitive_flexibility[d$multilingual=="multilingual"]), 2),
           " (SD = ",
           round(sd(d$cognitive_flexibility[d$multilingual=="multilingual"]), 2),
           ").")`'

- Simple comparisons with scientifically-meaningful units.
- What if we could do the same for statistical models?

## Predictions, not parameters
- Main idea: rather than directly interpret parameters, use the model to make predictions
    - contrasts between different predictions consitute *marginal effects*
- The `marginaleffects` package by Vincent Arel-Bundock makes these calculations easy for a wide range of models in both R and Python.

## In simple models, a parameter might be all we need

:::: {.columns}
::: {.column width="60%"}
- Example: do multilingual children have greater cognitive flexibility than monolingual children?
    - *Data*: 200 children from some population
    - *Estimand*: what is the average difference in cognitive flexibility (measured by a psychometric instrument ranging from 0 to 100) between bilingual and monolingual children?
    - *Estimate*: 'Multilingual participants have an average cognitive flexibility score of 11.908 [5.386, 18.430] points higher than monolingual participants.'
:::

::: {.column width="40%"}
::: {.fragment}
```{r, echo=FALSE}
ggplot(d, aes(x = multilingual, y = cognitive_flexibility, color = multilingual)) +
    geom_jitter(alpha = 0.7, width = 0.05) +
    geom_boxplot(alpha = 0.1) +
    theme_classic(base_size = 24) +
    theme(legend.position = "none") +
    labs(x = "", y = "Cognitive flexibility")
```
:::

::: {.fragment}
```{r}
summary(lm(cognitive_flexibility ~ multilingual))
```
:::
:::
::::

## A regression is a machine that makes predictions

$$ \text{Cognitive flexibility} = \alpha + \beta \times \text{Multilingual} + \epsilon $$
$$ \epsilon \sim \text{Normal}(0, \sigma^2) $$

- The parts of the machine are the parameters ($\alpha, \beta, \sigma$):
  - To make a prediction for a monolingual child, just take the intercept ($\alpha$).
  - To make a prediction for a multilingual child, add the coefficient for multilingual ($\beta$) to the intercept.
- Linear regression is such a simple machine that it offers a 1:1 mapping between the parameters and the estimand (average difference between bilingual and monolingual children).

## Interactions

![](figures/hall_of_mirrors.png)

## Interactions imply heterogeneity

:::: {.columns}

::: {.column width="60%"}
- If we add an interaction term (moderator) to our model, the estimand is no longer reducible to a single parameter.
- To see why, let's formalize the estimand:
  - For a given child, let $Y_i(\text{multilingual})$ be the outcome if the child is bilingual and $Y_i(\text{monolingual})$ be the outcome if the child is monolingual. 
  - The estimand is the average difference in potential outcomes: $\frac{1}{N} \sum_{i=1}^N [Y_i(\text{multilingual}) - Y_i(\text{monolingual})]$. Known as the *average treatment effect* (ATE), or average marginal effect (AME).
  - In our simple linear regression, all children are identical, conditional on their mono/multilingual status, which allows us to reduce the estimand to a single parameter.
:::

::: {.column width="40%"}
::: {.fragment}
![](figures/ATE.png){width="75%"}
:::
:::

::::

## Interactions imply heterogeneity

What if age moderates the effect of multilingualism?

:::: {.columns}
::: {.column width="60%"}
```{r}
m_centered <- lm(cognitive_flexibility ~ multilingual * age_c)

summary(m_centered)
```
:::

::: {.column width="40%"}
```{r}
ggplot(d, aes(x = age_c, y = cognitive_flexibility, color = multilingual)) +
    geom_point(alpha = 0.7) +
    geom_smooth(method = "lm", se = FALSE) +
    theme_classic(base_size = 28) +
    theme(legend.title = element_blank()) +
    scale_color_manual(values = c("monolingual" = "royalblue", 
                                "multilingual" = "darkorange")) +
    labs(x = "Age (centered)", y = "Cognitive flexibility")
```
:::
::::

- Which coefficient corresponds to the estimand (average marginal effect)?
    - None! The AME depends on the distribution of the moderator (age):
        - The magnitude of the multilingual effect depends on age--now it matters which children we are averaging over.

## Meaning of interaction term is highly contextual

On the previous slide, the interaction term was mean-centered. What if we use the raw age variable instead?

:::: {.columns}
::: {.column width="60%"}
```{r}
m_uncentered <- lm(cognitive_flexibility ~ multilingual * age)

summary(m_uncentered)
```
:::

::: {.column width="40%"}
```{r}
ggplot(d, aes(x = age, y = cognitive_flexibility, color = multilingual)) +
    geom_point(alpha = 0.7) +
    geom_smooth(method = "lm", se = FALSE) +
    theme_classic(base_size = 28) +
    theme(legend.title = element_blank()) +
    scale_color_manual(values = c("monolingual" = "royalblue", 
                                "multilingual" = "darkorange")) +
    labs(x = "Age", y = "Cognitive flexibility")
```
:::
::::

- The data visualization looks the same, but the model seems to be telling us something different.
    - In fact, the effect we are seeking is 'lost in translation'.
    - By generating predictions from the model, these contradictions will melt away.

## Getting started with `marginaleffects`: predictions

```{r, echo = T}
library(marginaleffects)

uncentered_model <- lm(cognitive_flexibility ~ multilingual * age, data = d)

preds <- predictions(uncentered_model)

preds |> 
    as.data.frame() |> 
    select(rowid, multilingual, age, estimate, conf.low, conf.high) |> 
    print(digits = 2)
```

## Getting started with `marginaleffects`: predictions

```{r, echo = T}
library(marginaleffects)

centered_model <- lm(cognitive_flexibility ~ multilingual * age_c, data = d)

preds <- predictions(centered_model)

preds |> 
    as.data.frame() |> 
    select(rowid, multilingual, age_c, estimate, conf.low, conf.high) |> 
    print(digits = 2)
```

## From predictions to comparisons

```{r, echo = T}
comparisons <- comparisons(uncentered_model, variables = "multilingual")

comparisons |> 
    as.data.frame() |> 
    select(rowid, contrast, age, estimate, conf.low, conf.high) |> 
    print(digits = 2)
```

## Calcualting average marginal effects

```{r, echo = T}
AME <- avg_comparisons(uncentered_model)

AME |> 
    as.data.frame() |> 
    select(term, contrast, estimate, conf.low, conf.high) |> 
    print(digits = 2)
```

## marginaleffects can also make plots

```{r, echo = T}
plot_predictions(uncentered_model, condition = list("multilingual"))
```

## marginaleffects can also make plots

```{r, echo = T}
plot_predictions(uncentered_model, condition = list("age"))
```

## marginaleffects can also make plots

```{r, echo = T}
plot_predictions(uncentered_model, condition = list("age", "multilingual"))
```

## marginaleffects can also make plots

Because the plots are made with `ggplot2`, we can customize them as we like.

```{r, echo = T}
plot_predictions(uncentered_model, condition = list("age", "multilingual")) +
    theme_classic(base_size = 24) +
    theme(legend.title = element_blank()) +
    scale_color_manual(values = c("monolingual" = "royalblue", 
                                "multilingual" = "darkorange")) +
    scale_fill_manual(values = c("monolingual" = "royalblue", 
                                "multilingual" = "darkorange")) +
    labs(x = "Age", y = "Cognitive flexibility score")
```

## Generalized linear models

- GLMs such as logistic regression and Poisson regression are also supported by `marginaleffects`.

- Good news for us, because *everything* interacts in a GLM due to the link function (e.g., logit, log, softmax). Extremely easy to mislead ourselves if we try to interpret parameters.

## Logistic regression

- Hypothetical dataset: Touchscreen experiment with Chimpanzees
    - After viewing a stimulus, the chimpanzee touches the screen on either the 'Agent' or the 'Patient' in a scence.
    - Estimand: what is the average *difference* in the probability of touching the 'Agent' side between two conditions ('experimental' vs 'control')?
        - $\frac{1}{N} \sum_{i=1}^N [P(Y_i = \text{Agent} | \text{experimental}) - P(Y_i = \text{Agent} | \text{control})]$

![](figures/chimp_touchscreen.webp)

## Logistic regression

```{r}
N <- 60

condition <- rep(c("experimental", "control"), N/2)
sex <- sample(c("male", "female"), N, prob = c(0.35, 0.65), replace = TRUE)
mu <- 0.4 + (1.5 * (condition == "experimental")) + (0.25 * (sex == "male"))

agent <- rbinom(N, 1, plogis(mu))

d <- data.frame(agent = agent, condition = condition, sex = sex)
```

$$ \text{Agent} \sim \text{Bernoulli}(\pi) $$
$$ \pi = \text{logit}^{-1}(\alpha + \beta \times \text{experimental}) $$

```{r}
logistic_model <- glm(agent ~ condition, data = d, family = binomial)

summary(logistic_model)
```

## Logistic regression

![](figures/logistic_compression.png){width="50%"}

- Even with just a single predictor, we cannot get our estimate from looking at model coefficients. 

- Due to the link function, the effect of the experimental condition depends on the intercept.

- 'Mechanistic' rather than conceptual interaction.
    - To get the AME we need to calculate:
        - $\frac{1}{1 + e^{-(\alpha + \beta \times \text{experimental})}} - \frac{1}{1 + e^{-\alpha}}$
        
## *marginaleffects* to the rescue

```{r, echo = T}
AME <- avg_comparisons(logistic_model, variables = "condition")

AME |> 
    as.data.frame() |> 
    select(term, contrast, estimate, conf.low, conf.high) |> 
    print(digits = 2)
```

```{r, echo = T}
plot_predictions(logistic_model, condition = list("condition"))
```

- NOTE: I should write out the estimate in line with the original goal to make the outputs easier to report and interpret.

## But how does it work?

- For frequentist models, `marginaleffects` by default uses the delta method of numerical differentiation to calculate standard errors
    - Various bootstrap and weighting methods supported

- For Bayesian models (e.g., fit with `brms`), `marginaleffects` uses the same method, but with full posterior draws rather than approximate standard errors

## Log-linear models

Example: reaction time to a stimulus

$$ \text{Reaction time} = \alpha + \beta \times \text{Condition} + \epsilon $$

## Non-linear effects

- Often our hypotheses are only directional, and we don't anticipate or have specific hypotheses about non-linearity

- Again, for GLMs, *all* continous effects are non-linear...

## Marginal effect at the mean

- So far, we have been calculating average marginal effects (AMEs), where we make comparisons changing only the predictor of interest.

- Marginal effect at the mean (MEM): 
    - 

## Bigger picture

- Interpreting regression models is a full of traps that can substantivey change our conclusions. Working with predictions and marginal effects allows us to avoid many of these traps.

## Average slopes

- Rather than setting everything to the mean, what is the average slope if we changed the predictor by a very small amount?

## Custom comparisons

- We don't have to use the default comparisons (group-contrasts or 1-unit changes)
- Examples (with marginal effects code)

## Can marginal effects improve the reliability of science?

- On the one hand, we can avoid falling into many of the traps of interpreting model parameters.

- On the other hand, this way of doing things brings the *estimand* into focus. We are being more explicit about the quantity we are trying to estimate--*which is not tied to any particular model.*

## Red Card Dataset

2,053 soccer players in the first male divisions of England, Germany, France, and Spain in the 2012â€“2013 season.

Outcome: number of red cards recieved for 146,028 player-referee dyads.

![](figures/red_card_in_soccer.jpg){width="50%"}

## Many analysts, many estimates

"Are soccer players with dark skin tone more likely than those with light skin tone to receive red cards from referees?"

![](figures/many_analysts_title.png){width="65%"}

## Many analysts, many estimates

"Are soccer players with dark skin tone more likely than those with light skin tone to receive red cards from referees?"

![](figures/many_analysts_results.jpeg){width="80%"}

----

![](figures/hidden_universe_uncertainty.png){width="80%"}

----

## Who watches the watchmen? Reanalysis of the meta-analysis

![](figures/many_analysts_reanalysis.png){width="80%"}

## Many analysts, many *estimands*

![](figures/causal_diagrams_RQ.jpeg){width="80%"}

"Thus, we argue that the results obtained in the CSI showed such a large variation because the 29 teams pursued (at least) four different research questions and therefore used different research designs."

----

![](figures/many_analysts1.png)

----

Controlled direct effect: $E[Y(\text{dark}) - Y(\text{light}) | M = m]$

![](figures/many_analysts2.png)

----

## More effort needed in science to connect theory to the quantities we report in our papers

![Three critical choices in quantitative research. From: Lundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532-565.](figures/estimand_flow.png)

## Many choices of estimand



## Breakout session (10-15 minutes)

Goal:
    - Write down the *estimand* for one of your research questions
        - Remember: this is a unit-specific comparison, ideally with reference to a specific population.
    - Draft a statistical model that you could use as your *estimator*
    - Write down the marginaleffects code that would yield your *estimate*
    - If you don't have the relevant software on your laptop, find a neighbor who does.
    - Pseudocode is fine!

## Report-back/Q&A session

- How did it go? What friction did you encounter?

# Part 2: Work-flow, code review. Fear is the mind killer

This section is about computation, but it is also about anxiety and the fear of making mistakes.

## Truth: everyone has bugs in their code

### Kim-Jung Gi drawing gif here. Disconnect between what we see in published reserach and how statistical modelling works in practice.

Statistics can feel like a thankless list of things that all have to be right or else *nothing* is right.
- Not totally wrong, but leads to anxiety

## Academic time allocation

- Academics consistently underestimate the time it takes to do...everything
    - coding tasks most under-estimated!

## Harsh realities

- We feel that we should be going faster
- The more we improve statistical practice in science, the more we ask of scientists
- We need workflows that help keep us sane

## Code review anxiety

- 7 years ago, I had published my first, first-authored paper. The data and code were posted on GitHub.

- A few days after the paper went live, I got a notification for a pull request on my repo: Bret Beheim had found a bug in my code.

- In the end, it was inconsequential. But it could have been a disaster.

### Slow is smooth, smooth is fast

### Fit fast, fail fast

- Recall that a regression is a machine with many moving parts. Just as we can't understand the joint behavior from the sum of the parts, we often cannot understand a model's failures from the individual parts.

- Need to simply the model until it works, then gradually add back complexity to diagonose what went wrong.

- Folk theorem of statistical computing: 
Problems in statistical computing are often caused by problems in the model/data.

## Multiverse of madness

- Specification curves
- Key idea: figure out sensitivity of estimates to reasonable range of model specifications, and which qualitative insights are robust to these choices.


