---
title: "Making statistics work for (evolutionary language) scientists"
author: "Erik J. Ringen"
format:
  revealjs:
    incremental: true
    slide-number: true
    theme: default
    smaller: true
---

## Introduction

This session is about how statistics can be in service of science.
- That point might sound mundane, but I think it is actually profound.

- Key ideas:
    - Scientist have to learn the language of statistical models
    - But a lot gets lost in translation, particularly when we try to translate back to substantive scientific questions from the output of statistical models.

- Goals:
    - Teach you a very general way to translate statistical models back into substantive scientific questions.
    - 

# Part 1: Marginal effects

## About me

- I earned my PhD in Evolutionary Anthropology <span class="fragment strike">during the 447th lunation of the third millennium, when Mars was at an orbital longitude of ~187 degrees</span><span class="fragment"> in May 2023</span>

- To get from Zurich to here, I travelled <span class="fragment strike">807 light-microseconds</span><span class="fragment"> 242 kilometers</span>

## The way we report statistics is often confusing (and misleading)

![](figures/confusing_stats.png)

## The way we report statistics is often confusing (and misleading)

![](figures/regression_table.png)

---

### In contrast, descriptive statistics and data viz are easy to understand

```{r}
set.seed(123)
library(tidyverse)
N <- 125

multilingual <- sample(c(0, 1), N, replace = TRUE)
cognitive_flexibility <- rnorm(N, multilingual*0.45, 0.5)
cognitive_flexibility  <- pnorm(cognitive_flexibility) * 100

d <- data.frame(multilingual = ifelse(multilingual == 0, "monolingual", "multilingual"), cognitive_flexibility = cognitive_flexibility)

ggplot(d, aes(x = multilingual, y = cognitive_flexibility, color = multilingual)) +
    geom_jitter(alpha = 0.7, width = 0.05) +
    geom_boxplot(alpha = 0.1) +
    theme_classic(base_size = 24) +
    theme(legend.position = "none") +
    labs(x = "", y = "Cognitive flexibility score")
```

'`r paste0("Monolingual participants have a mean cognitive flexibility score of ", round(mean(d$cognitive_flexibility[d$multilingual=="monolingual"]), 2), ", while multilingual participants have a mean score of ", round(mean(d$cognitive_flexibility[d$multilingual=="multilingual"]), 2), ".")`'

- Simple comparisons with scientifically-meaningful units.
- What if we could do the same for statistical models?

## Predictions, not parameters
- Big idea: rather than interpret specific parameters of a model, we can use the model to make predictions
    - contrasts between different predictions consitute *marginal effects*
- The `marginaleffects` package makes these calculations easy for a wide range of models in both R and Python.

## Problems with parameters



- Quantitative research relies on models with many moving parts (i.e., parameters).

- In all but the simplest models, no single parameter can answer our research question. Direct interpretation of model coefficients is unintuitive at best, misleading at worst.

- We can do better. Use the model to calculate *marginal effects* that are easy to interpret and communicate.
    - marginal effects are unit-specific contrasts, i.e., between two groups or between values of a continuous predictor.
    - The `marginaleffects` package makes these calculations easy for a wide range of models in both R and Python.

## In simple models, a parameter might be all we need

:::: {.columns}
::: {.column width="50%"}
- Example: do bilingual children have greater cognitive flexibility than monolingual children?
    - Data: 200 children from some population
    - Estimand: what is the average difference in cognitive flexibility (measured by a psychometric instrument ranging from 0 to 100) between bilingual and monolingual children?
:::

::: {.column width="50%"}
```{r, echo=FALSE}
library(tidyverse)

N <- 200

bilingual <- sample(c(0, 1), N, replace = TRUE)
cognitive_flexibility <- rnorm(N, bilingual*0.45, 1)
cognitive_flexibility  <- pnorm(cognitive_flexibility) * 100

d <- data.frame(bilingual = ifelse(bilingual == 0, "monolingual", "bilingual"), cognitive_flexibility = cognitive_flexibility)

ggplot(d, aes(x = bilingual, y = cognitive_flexibility, color = bilingual)) +
    geom_jitter(alpha = 0.7, width = 0.05) +
    geom_boxplot(alpha = 0.1) +
    theme_classic(base_size = 24) +
    theme(legend.position = "none") +
    labs(x = "", y = "Cognitive flexibility")
```

```{r}
lm(cognitive_flexibility ~ bilingual)
```
:::

::::

### So we start out advocating for unit-specific contrasts, but then we realize that we need to make a choice about what we want to contrast. So need to define the estimand, and the connection between theory, estimand, and estimator.

# Formally defining the estimand

- For a given child, let $Y_i(\text{bilingual})$ be the outcome if the child is bilingual and $Y_i(\text{monolingual})$ be the outcome if the child is monolingual. The estimand is the average difference in potential outcomes: $\frac{1}{N} \sum_{i=1}^N [Y_i(\text{bilingual}) - Y_i(\text{monolingual})]$.

- In other words, we imagine that we could randomly assign each child to be bilingual or monolingual, and then observe the difference in their individual outcomes. So, how does this connect to our model?

- Recall our simple linear model: $Y_i = \alpha + \beta \text{bilingual}_i + \epsilon_i$

- For each child $i$, the expected value of the outcome if the child is bilingual is $Y_i(\text{bilingual})$ = $\alpha + \beta$.
- The expected value of the outcome if the child is monolingual is $Y_i(\text{monolingual})$ = $\alpha$.
- Therefore the average difference in potential outcomes is simply ($\alpha + \beta$) - $\alpha$ = $\beta$.
    - It will almost never be this simple in real research contexts.

# Why we need to define the estimand
- Redcard dataset: diferences between analysts dissipates once we clearly define the estimand.

# Interactions

![](figures/hall_of_mirrors.png)

# Adding complexity: interactions

- What if the effect of bilingualism depends on the child's age (an interaction term)?
- Formula: $Y_i = \alpha + \beta \text{bilingual}_i + \gamma \text{age}_i + \delta \text{bilingual}_i \times \text{age}_i + \epsilon_i$
- For each child $i$, the expected value of the outcome if the child is bilingual is $Y_i(\text{bilingual})$ = $\alpha + \beta + \gamma \text{age}_i + \delta \text{age}_i$.
- The expected value of the outcome if the child is monolingual is $Y_i(\text{monolingual})$ = $\alpha + \gamma \text{age}_i$.
- The estimand is the average difference in potential outcomes: $\frac{1}{N} \sum_{i=1}^N [Y_i(\text{bilingual}) - Y_i(\text{monolingual})] = \frac{1}{N} \sum_{i=1}^N [(\alpha + \beta + \gamma \text{age}_i + \delta \text{age}_i) - (\alpha + \gamma \text{age}_i)] = \frac{1}{N} \sum_{i=1}^N (\beta + \delta \text{age}_i) = \beta + \delta \bar{\text{age}}$.
- Thus, the marginal effect is no longer reducible to a single parameter.

# Once we start using generalized linear models, everything interacts!


# Many types of marginal effects

- Average marginal effect
- Marginal effect at the mean
- Conditional marginal effect
- Average slope
- Takeaway: statisticians are terrible at naming things.

---

![Three critical choices in quantitative research. From: Lundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532-565.](figures/estimand_flow.png)

---

![Three critical choices in quantitative research. From: Lundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532-565.](figures/estimand_flow_highlight.png)

### A regression is a machine with many moving parts

# Break/Q&A sesion

# Part 2: Work-flow, code review. Fear is the mind killer

This section is about computation, but it is also about anxiety and the fear of making mistakes.

## Truth: everyone has bugs in their code

### Kim-Jung Gi drawing gif here. Disconnect between what we see in published reserach and how statistical modelling works in practice.

Statistics can feel like a thankless list of things that all have to be right or else *nothing* is right.
- Not totally wrong, but leads to anxiety

### Slow is smooth, smooth is fast

### Fit fast, fail fast

- Recall that a regression is a machine with many moving parts. Just as we can't understand the joint behavior from the sum of the parts, we often cannot understand a model's failures from the individual parts.

- Need to simply the model until it works, then gradually add back complexity to diagonose what went wrong.

- Folk theorem of statistical computing: 
Problems in statistical computing are often caused by problems in the model/data.

## Multiverse of madness

- Specification curves
- Key idea: figure out sensitivity of estimates to reasonable range of model specifications, and which qualitative insights are robust to these choices.